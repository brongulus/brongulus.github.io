<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>bacchanalian madness</title>
    <link>https://brongulus.github.io/</link>
    <description>Recent content on bacchanalian madness</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://brongulus.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>About</title>
      <link>https://brongulus.github.io/about/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://brongulus.github.io/about/about/</guid>
      <description>Hi! I&amp;rsquo;m Prashant.</description>
    </item>
    
    <item>
      <title>Creating a blog using ox-hugo, org mode and github pages</title>
      <link>https://brongulus.github.io/blog/blog-creation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://brongulus.github.io/blog/blog-creation/</guid>
      <description>I was going to make a post explaining how I made this blog but it was rendered pretty useless by this. So yeah, I might archive this later.
  Install hugo from your package manager.
  Create a new site:
hugo new site blog   Add a theme:
cd blog git init git submodule add &amp;lt;theme_url&amp;gt; themes/&amp;lt;name&amp;gt;   Install ox-hugo in emacs
;; goes in packages.el (package!</description>
    </item>
    
    <item>
      <title>Differential Geometry</title>
      <link>https://brongulus.github.io/notes/dg-notes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://brongulus.github.io/notes/dg-notes/</guid>
      <description>Theory of Space Curves Representation of space curves  Level Curve: f(x,y,z) = C From level curves to parametrized curves: \(y=x^{2} &amp;lt;&amp;mdash;&amp;ndash;&amp;gt; \gamma(t)=(\gamma_{1}(t),\gamma_{2}(t))\) Taking \(\gamma_{1}(t)=t\), we get \(\gamma_{2}(t)=t^{2}\) hence the parametrization is \(\gamma(t)=(t,t^{2})\) NOTE: Check if domain of x satisfies domain of t or not. That is, the same parametrisation can be represented as \((t^{2}.t^{4})\) or \((t^{3},t^{6})\) but only the latter is a correct representation. From parametrized curves to level curves: \(\gamma(t)=(cos^{3}t,sin^{3}t)\) &amp;lt;&amp;mdash;&amp;mdash;&amp;gt; F(x,y)=C; Using \(sin^{2}t+cos^{2}t=1\) we get, \(x^{2/3}+y^{2/3}=1\) as the level curve.</description>
    </item>
    
    <item>
      <title>Microprocessors and Interfacing</title>
      <link>https://brongulus.github.io/notes/microprocessors-notes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://brongulus.github.io/notes/microprocessors-notes/</guid>
      <description>Programmer&amp;rsquo;s Model 8086   </description>
    </item>
    
    <item>
      <title>Morphosyntactic Tagging with a Meta-BiLSTM Model - An Overview</title>
      <link>https://brongulus.github.io/blog/nnfl-paper/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://brongulus.github.io/blog/nnfl-paper/</guid>
      <description>(Subtitle: I had shingles, which is a painful disease.) This post contains a complete overview of the titled paper and provides a basic outline of related concepts. This paper aims to investigate to what extent having initial sub-word and word context insensitive representations affect performance.
Abstract  RNN leads to advances in speech tagging accuracy Zeman et al Common thing among models, rich initial word encodings. Encodings are composed of recurrent character-based representation with learned and pre-trained word embeddings1.</description>
    </item>
    
  </channel>
</rss>
